# faices
### Contributors: Charlie Laursen, Kyle Downing

Class project for **Privacy Enhancing Technologies** (CSCI-497) at Western Washington University. 

Analysis of facial recognition and verification systems on AI generated facial images.

---


Facial recognition is increasingly used as a trusted method to identify individuals. Facial recognition is used in many applications, including authentication for unlocking personal devices or in identifying individuals in digital images. Simultaneously, we have seen the quality of Artificial Intelligence systems increase and these systems become more widely available to the general public. 

With the ability to recreate a person's face digitally, people could use AI generated images of real faces in an effort to create fraudulent media to tarnish a person's identity. People generally speculate about whether digital media being AI generated, but sometimes cannot determine with absolute certainty. 

Given the multiple instances of ongoing or future privacy violations, our project scope is generalized to focus on the question of the susceptibility of facial recognition models against AI generated faces. We will look at face verification between a set of AI generated faces and real faces, and between a set of real faces and AI generated faces. In the first scenario, we will look to answer whether facial recognition models trained on synthetic face data neutralize privacy protections such as Fawkes. In the second scenario, we will answer whether AI generated facial images produce sufficiently similar embeddings to real faces to the point where they can pass verification against facial recognition systems.
